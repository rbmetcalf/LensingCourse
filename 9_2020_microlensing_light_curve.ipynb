{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-grave",
   "metadata": {},
   "source": [
    "# Light curve in single lens microlensing events\n",
    "\n",
    "In the case of a galactic microlensing event prouduced by a single lens, the Einstein radius is\n",
    "$$\n",
    "\\theta_E\\approx 1 mas \\left(\\frac{M}{M_\\odot}\\right)^{1/2}\\left(\\frac{D}{10 \\mathrm{kpc}}\\right)^{-1/2} \\;.\n",
    "$$\n",
    "Since this is the scale of separation between the images in the microlensing event, we may conclude that the effect is not appreciable.\n",
    "\n",
    "However, if the source moves in lens centered coordinates with some transverse velocity $v$ or relative motion\n",
    "$$\n",
    "\\mu_{rel}=\\frac{v}{D_L} \\;,\n",
    "$$\n",
    "then, during the microlensing event, the magnification of the source changes as\n",
    "$$\n",
    "\\mu(t)=\\frac{y^2(t)+2}{y(t)\\sqrt{y^2(t)+4}}\n",
    "$$\n",
    "with \n",
    "$$\n",
    "y(t)=\\sqrt{y_0^2+\\left(\\frac{t-t_0}{t_E}\\right)^2} \\;.\n",
    "$$\n",
    "\n",
    "The quantity $t_E$ is the Einstein crossing time\n",
    "$$\n",
    "t_E = \\frac{D_L\\theta_E}{v} = \\frac{\\theta_E}{\\mu_{rel}}\n",
    "$$\n",
    "which is of order\n",
    "$$\n",
    "t_E\\approx 19\\; \\mathrm{days} \\; \\sqrt{4\\frac{D_{L}}{D_{S}}\\left(1-\\frac{D_{L}}{D_{S}}\\right)}\\left(\\frac{D_{S}}{8 \\mathrm{kpc}}\\right)^{1/2}\\left(\\frac{M}{0.3 M_\\odot}\\right)^{1/2}\\left(\\frac{v}{200 \\mathrm{km}/s}\\right)^{-1}\n",
    "$$\n",
    "\n",
    "In the following, we will compute amplitude of the effect, to understand if it is measurable.\n",
    "\n",
    "We define two python classes, one for the source and one for the lens. The first is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import constants as const \n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "\n",
    "class point_source(object):\n",
    "    \n",
    "    def __init__(self,flux=1.0,ds=10.0,vel=200.):\n",
    "        \"\"\"\n",
    "        Initialize a point source.\n",
    "        Parameters:\n",
    "        - flux: baseline flux\n",
    "        - ds: source distance\n",
    "        - vel: source relative velocity\n",
    "        \"\"\"\n",
    "        self.ds=ds\n",
    "        self.flux=flux\n",
    "        self.vel=vel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-compression",
   "metadata": {},
   "source": [
    "We create a ```point_source``` by specifying its baseline flux, distance and relative velocity.\n",
    "\n",
    "The second class, ```point_lens```, contains several methods that implements the formulas shown above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class point_lens(object):\n",
    "\n",
    "    \"\"\" \n",
    "    Initialize a point lens.\n",
    "    Parameters:\n",
    "    - ps : point source\n",
    "    - mass : lens mass\n",
    "    - dl : lens distance\n",
    "    - t0 : time of minimal distance from the source\n",
    "           (magnification peak)\n",
    "    - y0 : impact parameter\n",
    "    \"\"\"\n",
    "    def __init__(self,ps,mass=1.0,dl=5.0,ds=8.0,t0=0.0,y0=0.1):\n",
    "        self.M=mass\n",
    "        self.dl=dl\n",
    "        self.ps=ps\n",
    "        self.y0=y0\n",
    "        self.t0=t0\n",
    "        self.tE=self.EinsteinCrossTime()\n",
    "        \n",
    "###################################################################        \n",
    "    # a function returning the Einstein radius\n",
    "    def EinsteinRadius(self):\n",
    "        mass=self.M*const.M_sun\n",
    "        G=const.G\n",
    "        c=const.c\n",
    "        # conversion factor: radian to arcsec \n",
    "        aconv=np.rad2deg(1.0)*3600.0*u.arcsecond \n",
    "        return((np.sqrt(4.0*(G*mass/c/c).to('kpc')*(self.ps.ds-self.dl)\n",
    "                        /self.dl/self.ps.ds/u.kpc))*aconv)\n",
    "    \n",
    "    # a function returning the Einstein radius crossing time\n",
    "    def EinsteinCrossTime(self):\n",
    "        theta_e=self.EinsteinRadius()\n",
    "        return(((theta_e.to('radian').value*self.dl*u.kpc).to('km')\n",
    "                /self.ps.vel/u.km*u.s).to('day'))\n",
    "    \n",
    "    # a function returning the coordinates of the unlensed source \n",
    "    # at time t\n",
    "    def y(self,t):\n",
    "        y1=(t-self.t0)/self.tE.value\n",
    "        y0=np.ones(len(t))*self.y0\n",
    "        return(y0,y1)\n",
    "\n",
    "    # the lens magnification as a function of time\n",
    "    def mut(self,t):\n",
    "        y0,y1=self.y(t)\n",
    "        y=np.sqrt(y0**2+y1**2)\n",
    "        return (self.ps.flux*(y**2+2)/y/np.sqrt(y**2+4))\n",
    "\n",
    "    # a function returning the coordinates of the x_+ image at time t\n",
    "    def xp(self,t):\n",
    "        y1, y2  = self.y(t)\n",
    "        Q = np.sqrt(y1**2 + y2**2 +4)/(np.sqrt(y1**2 + y2**2))\n",
    "        xp1= 0.5 * (1 + Q) * y1\n",
    "        xp2= 0.5 * (1 + Q) * y2\n",
    "        return(xp1, xp2)\n",
    "    \n",
    "    # a function retruning the coordinates of the x_- image at time t\n",
    "    def xm(self,t):\n",
    "        y1, y2  = self.y(t)\n",
    "        Q = np.sqrt(y1**2 + y2**2 +4)/(np.sqrt(y1**2 + y2**2))\n",
    "        xm1= 0.5 * (1 - Q) * y1\n",
    "        xm2= 0.5 * (1 - Q) * y2\n",
    "        return(xm1, xm2)\n",
    "    \n",
    "    # the magnification of the x_+ image\n",
    "    def mup(self,t):\n",
    "        y1, y2  = self.y(t)\n",
    "        yy=np.sqrt(y1**2+y2**2)\n",
    "        mup=0.5*(1+(yy**2+2)/yy/np.sqrt(yy**2+4))\n",
    "        return (mup)\n",
    "    \n",
    "    # the magnification of the x_- image\n",
    "    def mum(self,t):\n",
    "        y1, y2  = self.y(t)\n",
    "        yy=np.sqrt(y1**2+y2**2)\n",
    "        mum=0.5*(1-(yy**2+2)/yy/np.sqrt(yy**2+4))\n",
    "        return (mum)\n",
    "    \n",
    "    # a function returning the coordinate of the light centroid\n",
    "    def xc(self,t):\n",
    "        xp=self.xp(t)\n",
    "        xm=self.xm(t)\n",
    "        xc=(xp*np.abs(self.mup(t))+\n",
    "            xm*np.abs(self.mum(t)))/(np.abs(self.mup(t))+np.abs(self.mum(t)))\n",
    "        return (xc)\n",
    "\n",
    "    def xp_ext_source(self,t,r):\n",
    "        phi=np.linspace(0.0,2*np.pi,360)\n",
    "        dy1=r*np.cos(phi)\n",
    "        dy2=r*np.sin(phi)\n",
    "        y1,y2=self.y(t)\n",
    "        yy1=y1+dy1\n",
    "        yy2=y2+dy2\n",
    "        Q=np.sqrt(yy1**2+yy2**2+4.0)/np.sqrt(yy1**2+yy2**2)\n",
    "        xp1=0.5*(1+Q)*yy1\n",
    "        xp2=0.5*(1+Q)*yy2\n",
    "        return(xp1,xp2)   \n",
    "    \n",
    "    def xm_ext_source(self,t,r):\n",
    "        phi=np.linspace(0.0,2*np.pi,360)\n",
    "        dy1=r*np.cos(phi)\n",
    "        dy2=r*np.sin(phi)\n",
    "        y1,y2=self.y(t)\n",
    "        yy1=y1+dy1\n",
    "        yy2=y2+dy2\n",
    "        Q=np.sqrt(yy1**2+yy2**2+4.0)/np.sqrt(yy1**2+yy2**2)\n",
    "        xm1=0.5*(1-Q)*yy1\n",
    "        xm2=0.5*(1-Q)*yy2\n",
    "        return(xm1,xm2)\n",
    "    \n",
    "    def deltaxc(self,t):\n",
    "        y1,y2=self.y(t)\n",
    "        yy=(y1**2+y2**2)\n",
    "        return(y1/(yy+2),y2/(yy+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-insulin",
   "metadata": {},
   "source": [
    "The first argument in the ```__init__``` function is the instance of the ```point_source``` class. The other parameters are the lens mass and distance, the time of the magnification peak, and the impact parameter. The initialization function contains a call to a function to calculate the Einstein crossing time (```EinsteinCrossTime```). This function calls another function to calculate the Einstein radius (```EinsteinRadius```). \n",
    "\n",
    "We also define a function ```y``` which computes the source position relative to the lens at the time t, $\\vec y(t)$. Finally, the function ```mut``` calculates the magnification as a function of time.\n",
    "\n",
    "We assume that the source is at a distance of $D_S=8$ kpc and that its relative velocity is $v=200$ km/s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = point_source(flux=1.,ds=8.0,vel=200.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-auckland",
   "metadata": {},
   "source": [
    "We will display the light curves for a variety of impact parameters $y_0$. The choice of $t_0$ is not important, because we will display the light-curves as a function of $(t-t_0)/t_E$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the impact parameters\n",
    "y0=np.linspace(1.0,0.1,10)\n",
    "# passage at the minimum distance from the lens\n",
    "t0=365 # days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-gazette",
   "metadata": {},
   "source": [
    "We assume that the lens mass is $M=0.3 \\;M_\\odot$ and that the lens distance is $D_L=4$ kpc. For each value of the impact parameter, we can now calculate the magnification as a function of time as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the impact parameters and calculate\n",
    "# the lightcurves:\n",
    "\n",
    "for i in range(y0.size):\n",
    "    pl = point_lens(ps,mass=0.3,dl=4.0,t0=t0,y0=y0[i])\n",
    "    t=pl.t0+np.linspace(-2,2,200)*pl.tE.value\n",
    "    mut=pl.mut(t)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import cm \n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# create a color sequence using the rainbow color-map\n",
    "color=iter(cm.rainbow(np.linspace(0,1,y0.size)))\n",
    "\n",
    "xx=[-2,2]\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "ax[1].set_ylim([1.0,10.0])\n",
    "ax[1].set_xlim([-2,2])\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlabel(r'$(t-t_0)/t_E$',fontsize=23)\n",
    "ax[1].set_ylabel(r'$\\mu(t)$',fontsize=23)\n",
    "ax[1].set_yticks(np.arange(1, 11, 1.0))\n",
    "ax[1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "ax[1].xaxis.set_tick_params(labelsize=20)\n",
    "ax[1].yaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "# create a circle with radius 1 (the Einstein ring)\n",
    "circle=plt.Circle((0,0),1,color='black',fill=False)\n",
    "ax[0].set_xlim([-1.5,1.5])\n",
    "ax[0].set_ylim([-1.5,1.5])\n",
    "ax[0].add_artist(circle) # display the Einstein ring\n",
    "ax[0].plot([0.0],[0.0],'*',markersize=20,color='red')\n",
    "ax[0].xaxis.set_tick_params(labelsize=20)\n",
    "ax[0].yaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "# loop over the impact parameters and plot the light curves\n",
    "for i in range(y0.size):\n",
    "    c=next(color)\n",
    "    pl = point_lens(ps,mass=0.3,dl=4.0,t0=t0,y0=y0[i])\n",
    "    t=pl.t0+np.linspace(-2,2,200)*pl.tE.value\n",
    "    mut=pl.mut(t)\n",
    "    ax[1].plot((t-pl.t0)/pl.tE,mut,'-',color=c)\n",
    "    yy=[y0[i],y0[i]]\n",
    "    ax[0].plot(xx,yy,'--',color=c,lw=2)\n",
    "\n",
    "ax[0].set_xlabel(r'$y_1$',fontsize=23) \n",
    "ax[0].set_ylabel(r'$y_2$',fontsize=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-madagascar",
   "metadata": {},
   "source": [
    "To illustrate how the light curve changes as a function of other parameters, like the lens mass, the distance $D_L$, or the lens-source relative velocity $v_{rel}$, we must account for how $t_E$ depends on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_test=np.linspace(100.0,300.0,10)\n",
    "M_test=np.logspace(-1,1,10)\n",
    "d_test=np.linspace(0.01,8.0*0.99,10)\n",
    "\n",
    "\n",
    "t=t0+np.linspace(-75,75,500)\n",
    "\n",
    "fig,ax=plt.subplots(1,3,figsize=(18,6))\n",
    "\n",
    "color=iter(cm.rainbow(np.linspace(0,1,v_test.size)))\n",
    "for i in range(len(v_test)):\n",
    "    ps = point_source(flux=1.,ds=8.0,vel=v_test[i])\n",
    "    pl = point_lens(ps,mass=0.3,dl=4.0,t0=t0,y0=y0.min())\n",
    "    t_=(t-t0)\n",
    "    c=next(color)\n",
    "    mut=pl.mut(t)\n",
    "    ax[0].plot(t_,mut,'-',color=c)\n",
    "    ax[0].set_title(r'$v_{rel}$',fontsize=25)\n",
    "    \n",
    "color=iter(cm.rainbow(np.linspace(0,1,v_test.size)))\n",
    "ps = point_source(flux=1.,ds=8.0,vel=200)\n",
    "for i in range(len(M_test)):\n",
    "    pl = point_lens(ps,mass=M_test[i],dl=4.0,t0=t0,y0=y0.min())\n",
    "    t_=(t-t0)\n",
    "    c=next(color)\n",
    "    mut=pl.mut(t)\n",
    "    ax[1].plot(t_,mut,'-',color=c)\n",
    "    ax[1].set_title(r'$Mass$',fontsize=25)\n",
    "    \n",
    "color=iter(cm.rainbow(np.linspace(0,1,v_test.size)))\n",
    "for i in range(len(d_test)):\n",
    "    pl = point_lens(ps,mass=0.3,dl=d_test[i],t0=t0,y0=y0.min())\n",
    "    t_=(t-t0)\n",
    "    c=next(color)\n",
    "    mut=pl.mut(t)\n",
    "    ax[2].plot(t_,mut,'-',color=c)\n",
    "    ax[2].set_title(r'$D_{L}$',fontsize=25)        \n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].xaxis.set_tick_params(labelsize=20)\n",
    "    ax[i].yaxis.set_tick_params(labelsize=20)\n",
    "    ax[i].set_yticks(np.arange(1, 11, 1.0))\n",
    "    ax[i].set_xlabel(r'$(t-t_0)$',fontsize=23)\n",
    "    ax[i].set_ylabel(r'$\\mu(t)$',fontsize=23)\n",
    "    ax[i].set_ylim([1.0,12.0])\n",
    "    ax[i].set_xlim([t.min()-t0,t.max()-t0])\n",
    "    ax[i].set_yscale('log')\n",
    "    ax[i].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "    \n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-camel",
   "metadata": {},
   "source": [
    "# Fitting the lightcurve\n",
    "\n",
    "The microlensing lightcurve is defined by the parameters $t_0$, $y_0$, and $t_E$. This last quantity depends also on $M$, $v_{rel}$, $D_L$, and $D_S$. Besides, the lighcurve normalization depends on the baseline flux $f$. Once a microlensing event has been detected and the light-curve has been measured, how precisely can we measure all these parameters? \n",
    "\n",
    "Here, we set up the following experiment:\n",
    "\n",
    "* we simulate the observation of a microlensing event and generate synthetic data, including measurement errors;\n",
    "* we use the package ```lmfit``` to fit the data;\n",
    "* we perform a bayesian analysis using the package ```emcee``` to estimate the posterior probability distributions of the parameters.\n",
    "\n",
    "We assume that the lens has a mass of  $M=0.3 M_\\odot$ and is at a distance of $D_L=4$ kpc. We further assume that the  source at a distance of $D_S=8$ kpc. The source baseline flux is $f=10$ (the units are arbitrary) and the impact parameter is $y_0=0.3$. The relative velocity of the source is $v=210$ km/s. We assume that we could monitor the source star for a long period (2 years) and collect data with constant cadence. This is clearly unrealistic, but we want to test a very ideal situation. In addition, we assume that the errors on the photometric measurement are at the level of $5\\%$. The peak magnification occurs at $t_0=365$ days.\n",
    "\n",
    "The code used to generate the synthetic data is here below. We use the classes ```point_source``` and ```point_lens``` from the previous example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = point_source(flux=10.,ds=8.0,vel=210.)\n",
    "pl = point_lens(ps,mass=0.3,dl=4.0,t0=365,y0=0.3)\n",
    "t=np.linspace(0,730,730)\n",
    "mut=pl.mut(t)+(np.random.randn(len(t))*0.02)\n",
    "\n",
    "# we assign to the data some errors, which we assume to be a \n",
    "# constant fraction of the measurement\n",
    "emut=mut*0.05\n",
    "\n",
    "# data representation\n",
    "fig,ax=plt.subplots(1,1,figsize=(18,8))\n",
    "ax.errorbar(t, mut,emut)\n",
    "ax.set_xlabel('t [days]',fontsize=20)\n",
    "ax.set_ylabel('flux',fontsize=20)\n",
    "ax.xaxis.set_tick_params(labelsize=20)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "ax.set_xlim([0,730])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-candle",
   "metadata": {},
   "source": [
    "The light-curve is displayed in the figure above (blue points with error bars).\n",
    "\n",
    "As said, in order to fit the data, we use the python package ```lmfit```. This package allows to build complex fitting models for non-linear least-squares problems. The package documentation can be found at this [link](http://cars9.uchicago.edu/software/python/lmfit\\_MinimizerResult/intro.html).\n",
    "\n",
    "We begin by setting up some initial guesses for the model parameters, storing them in a {\\tt lmfit.Parameter} object, including also some plausible ranges where the parameters can vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "# initial guesses for the parameters:\n",
    "# t0, M_lens, DL, DS, vel, y0, flux0\n",
    "p = lmfit.Parameters()\n",
    "p.add_many(('t0', 400.,True,0,720), ('M_lens', 1.0, True, 0.001, 100.0), \n",
    "           ('DL', 5., True, 0.1, 10.), ('DS', 8., False, 5., 15.), \n",
    "           ('vel',250,True,50.,300.), ('y0',0.8, True, 0.01,1.0),\n",
    "           ('flux0',12, True, 8,12.0))\n",
    "# For each parameter, we specify a initial value, a flag, two other values\n",
    "# defining the search range. If the flag is True the parameter is free\n",
    "# to vary, otherwise it is fixed to the initial value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-benjamin",
   "metadata": {},
   "source": [
    "Then, we define a *cost* function to compare the data and the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(p,t,mut,emut):\n",
    "    ps = point_source(flux=p['flux0'],ds=p['DS'],vel=p['vel'])\n",
    "    pl = point_lens(ps,mass=p['M_lens'],dl=p['DL'],\n",
    "                    t0=p['t0'],y0=p['y0'])\n",
    "    res=(pl.mut(t)-mut)**2/emut\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-matter",
   "metadata": {},
   "source": [
    "This function returns the residuals between the model and the data.\n",
    "\n",
    "The next step is to minimize the cost function (i.e. the residuals) to fit the data. Several algorithms are available in ```lmfit```. Here, we perform the minimization using the Nelder-Mead optimization method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = lmfit.minimize(cost_function, p, method='Nelder',\n",
    "                    args=(t,mut,emut))\n",
    "\n",
    "# plot the maximum likelihood solution on the top of the data\n",
    "fig,ax=plt.subplots(1,1,figsize=(18,8))\n",
    "ax.errorbar(t, mut,emut)\n",
    "ax.set_xlabel('t [days]',fontsize=20)\n",
    "ax.set_ylabel('flux',fontsize=20)\n",
    "ax.xaxis.set_tick_params(labelsize=20)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "ax.set_xlim([0,730])\n",
    "\n",
    "ps_bf = point_source(flux=mi.params['flux0'],ds=mi.params['DS'],\n",
    "                     vel=mi.params['vel'])\n",
    "pl_bf = point_lens(ps_bf,mass=mi.params['M_lens'],dl=mi.params['DL'],\n",
    "                   t0=mi.params['t0'],y0=mi.params['y0'])\n",
    "\n",
    "ax.plot(t,pl_bf.mut(t),'r',lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-diesel",
   "metadata": {},
   "source": [
    "The red line in the Figure above shows the best fit lightcurve. The best fit parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmfit.printfuncs.report_fit(mi.params, min_correl=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-glass",
   "metadata": {},
   "source": [
    "The values of some of the input parameters are recovered almost perfectly: $t_0$, $y_0$, and $f$. Not surprisingly, the remaining parameters differ significanly from the truth. They are highly degenerate parameters, because they all concur to determine the value of $t_E$. Only the Einstein crossing time determines the shape of the light curve. \n",
    "\n",
    "We perform a Bayesian sampling of the posterior probability distribution of the parameters using the ```emcee``` Monte Carlo Markov Chain package (see e.g. [this link](https://twiecki.io/blog/2015/11/10/mcmc-sampling/)). The log-posterior probability of the model parameters, $p$, given the data $d$ is\n",
    "\\begin{equation}\n",
    "\\ln P(p|d) \\propto \\ln P(d|p)+\\ln P(p) \\;,\n",
    "\\end{equation}\n",
    "where $\\ln P(d|p)$ is the log-likelihood of the data given the model parameters and $\\ln P(p)$ is the log-prior. We assume a uniform prior, meaning that $\\ln P$ is zero if all the parameters are inside the bounds, and $-\\infty$ if any of the parameters is outside its limits.\n",
    "\n",
    "The log-likelihood function is \n",
    "\\begin{equation}\n",
    "\\ln P(d|p)=-\\frac{1}{2}\\sum_n \\left[\\frac{(model_n-data_n)^2}{s_n^2}+\\ln 2\\pi s_n^2\\right] \\;,\n",
    "\\end{equation}\n",
    "where $s_n$ is the data uncertainty.\n",
    "\n",
    "We calculate it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-likelihood function\n",
    "def lnprob(p,t,mut,emut):\n",
    "    from numpy import inf\n",
    "    resid = cost_function(p,t,mut,emut)\n",
    "    s = emut\n",
    "    resid *= resid/s/s\n",
    "    resid += np.log(2 * np.pi * s**2)\n",
    "    lnp=-0.5 * np.sum(resid)\n",
    "    return lnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-florida",
   "metadata": {},
   "source": [
    "The next step is to call the function ```minimize``` using the method ```emcee```. We use 100 walkers to explore the parameter space. We run a few  *burn-in* steps in each MCMC chain to let the walkers get settled into the maximum of the density. Then, we do a production run of 2000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = lmfit.minimize(lnprob, method='emcee',\n",
    "                     nan_policy='omit', \n",
    "                     nwalkers=100, burn=500, steps=2000, \n",
    "                     params=mi.params,\n",
    "                     progress=True,args=(t,mut,emut))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-pressing",
   "metadata": {},
   "source": [
    "Finally, we visualize the posterior probability distributions using the ```corner``` package. The function corner uses the samples saved in ``` res.flatchain``` to draw two-dimensional histograms showing the probability density in the planes defined by each couple of parameters. These 2D-histograms are very useful to highlight the existing correlations between $v_{rel}$, $D_L$, and $M$. Besides, ```corner``` also plots the marginalized one dimensional density distribution for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show corner plot (confidence limits, parameter distributions, correlations)\n",
    "import corner\n",
    "#figure=corner.corner(res.flatchain, labels=res.var_names, \n",
    "#                     truths=list(res.params.valuesdict().values()),\n",
    "#                     show_titles=True, title_kwargs={\"fontsize\": 12})\n",
    "\n",
    "figure=corner.corner(res.flatchain, labels=res.var_names, \n",
    "                     show_titles=True, title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-formation",
   "metadata": {},
   "source": [
    "We can now repeat the experiment by fitting $t_0$, $y_0$, $f$, and $t_E$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "# initial guesses\n",
    "p = lmfit.Parameters()\n",
    "p.add_many(('t0', 360.,True,0,720), ('tE', 20, True, 1, 100.0), \n",
    "           ('y0',0.2, True, 0.01,1.0),('flux0',12, True, 8,12.0))\n",
    "\n",
    "# new functions\n",
    "\n",
    "def mut_func_new(tE,y0,t0,t):\n",
    "    y=yt_new(tE,y0,t0,t)\n",
    "    return ((y**2+2)/y/np.sqrt(y**2+4))\n",
    "\n",
    "def yt_new(tE,y0,t0,t):\n",
    "    return (np.sqrt(y0**2+((t-t0)/tE)**2))\n",
    "\n",
    "\n",
    "# objective function\n",
    "def new_cost_function(p,t,mut,emut):\n",
    "\n",
    "    v = p.valuesdict()\n",
    "    res=(mut_func_new(v['tE'],v['y0'],v['t0'],t)*v['flux0']-mut)**2/emut\n",
    "\n",
    "    return (res)\n",
    "\n",
    "\n",
    "mi = lmfit.minimize(new_cost_function, p, method='Nelder',\n",
    "                    args=(t,mut,emut))\n",
    "lmfit.printfuncs.report_fit(mi.params, min_correl=0.5)\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(18,8))\n",
    "ax.errorbar(t, mut,emut)\n",
    "ax.set_xlabel('t [days]',fontsize=20)\n",
    "ax.set_ylabel('flux',fontsize=20)\n",
    "ax.xaxis.set_tick_params(labelsize=20)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "ax.set_xlim([0,730])\n",
    "\n",
    "ax.plot(t,mi.params['flux0']*mut_func_new(mi.params['tE'],\n",
    "                                          mi.params['y0'],mi.params['t0'],t),'r',lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new log-likelihood function\n",
    "def new_lnprob(p,t,mut,emut):\n",
    "    from numpy import inf\n",
    "    resid = new_cost_function(p,t,mut,emut)\n",
    "    s = emut\n",
    "    resid *= resid/s/s\n",
    "    resid += np.log(2 * np.pi * s**2)\n",
    "    lnp=-0.5 * np.sum(resid)\n",
    "    return lnp\n",
    "\n",
    "result = lmfit.minimize(new_lnprob, method='emcee',\n",
    "                     nan_policy='omit', \n",
    "                     nwalkers=100, burn=500, steps=2000, \n",
    "                     params=mi.params,\n",
    "                     progress=True,args=(t,mut,emut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure=corner.corner(res.flatchain, labels=res.var_names, \n",
    "                     show_titles=True, title_kwargs={\"fontsize\": 12})\n",
    "\n",
    "res.params.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-somerset",
   "metadata": {},
   "source": [
    "Clearly, all parameters are now recovered precisely and the correlations between them are negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb6bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602a31b",
   "metadata": {},
   "source": [
    "Here we read in a new lightcurve and assign the measured time, flux and error in the flux to the same variables used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('microlens_lightcurve.csv')\n",
    "print(df.head())\n",
    "\n",
    "t = df['time']\n",
    "mut = df['flux']\n",
    "emut = df['error']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f71abd",
   "metadata": {},
   "source": [
    "Now we can make a plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(18,8))\n",
    "ax.errorbar(t, mut,emut,linestyle='')\n",
    "ax.set_xlabel('t [days]',fontsize=20)\n",
    "ax.set_ylabel('flux',fontsize=20)\n",
    "\n",
    "ax.set_ylabel('flux',fontsize=20)\n",
    "ax.xaxis.set_tick_params(labelsize=20)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "ax.set_xlim([0,730])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fc8ce",
   "metadata": {},
   "source": [
    "We can find the best-fit parameters as follows.  We need to remake the parameter object with new guesses and ranges.  Then we can minimize the lose function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eeed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lmfit.Parameters()\n",
    "p.add_many(('t0', 360.,True,0,720), ('tE', 100, True, 1, 300.0), \n",
    "           ('y0',0.3, True, 0.01,1.0),('flux0',25, True, 0,30))\n",
    "\n",
    "mi = lmfit.minimize(new_cost_function, p, method='Nelder',\n",
    "                    args=(t,mut,emut))\n",
    "lmfit.printfuncs.report_fit(mi.params, min_correl=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67f728",
   "metadata": {},
   "source": [
    "Now we can find the errors and covariances for the parameters using Markov Chain Monte Carlo (MCMC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b26212",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = lmfit.minimize(new_lnprob, method='emcee',\n",
    "                     nan_policy='omit', \n",
    "                     nwalkers=100, burn=100, steps=2000, \n",
    "                     params=mi.params,\n",
    "                     progress=True,args=(t,mut,emut))\n",
    "\n",
    "figure=corner.corner(res.flatchain, labels=res.var_names, \n",
    "                     show_titles=True, title_kwargs={\"fontsize\": 12})\n",
    "\n",
    "res.params.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
